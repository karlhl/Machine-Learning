## A Pytorch Implementation of the Transformer Network
This repository includes pytorch implementations of ["Attention is All You Need"](https://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf) (Vaswani et al., NIPS 2017) and 
["Weighted Transformer Network for Machine Translation"](https://arxiv.org/pdf/1711.02132.pdf) (Ahmed et al., arXiv 2017)

## Reference
**Paper**
- Vaswani et al., "Attention is All You Need", NIPS 2017
- Ahmed et al., "Weighted Transformer Network for Machine Translation", Arxiv 2017

**Code**
- [jadore801120/attention-is-all-you-need](https://github.com/jadore801120/attention-is-all-you-need-pytorch)
- [OpenNMT/OpenNMT-py](https://github.com/OpenNMT/OpenNMT-py)
- [The Annotated Transformers](http://nlp.seas.harvard.edu/2018/04/03/attention.html)
