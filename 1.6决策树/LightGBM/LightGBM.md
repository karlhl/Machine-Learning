# LightGBM

GBDT的高效实现：pGBRT,XGBoost,LightGBM

原理上它和GBDT及XGBoost类似，都采用损失函数的负梯度作为当前决策树的残差近似值，去拟合新的决策树。

**XGBoost特点**

1.精准贪心算法：

优点：精准找到划分条件

缺点：每次迭代需要遍历整个训练数据，如果把整个训练数据装进内存则会限制训练数据的大小；如果不装进内存，反复地读写训练数据又会消耗非常大的时间。计算量大，内存占用大，容易过拟合

2.Level-wise迭代方式

预排序方法（pre-sorted）：首先，空间消耗大。这样的算法需要保存数据的特征值，还保存了特征排序的结果（例如排序后的索引，为了后续快速的计算分割点），这里需要消耗训练数据两倍的内存。其次时间上也有较大的开销，在遍历每一个分割点的时候，都需要进行分裂增益的计算，消耗的代价大。

优点：可以多线程，加速贪心算法

缺点：效率低下，产生不必要的叶结点

3.对cache优化不好

在预排序后，特征对梯度的访问是一种随机访问，并且不同的特征访问的顺序不一样，无法对cache进行优化。同时，在每一层长树的时候，需要随机访问一个行索引到叶子索引的数组，并且不同特征访问的顺序也不一样，也会造成较大的cache miss

**相比XGBoost优势：**

LightGBM比XGBoost快将近10倍，内存占用率大约为XGBoost的1/6，并且准确率也有提升。

概括来说，lightGBM主要有以下特点：

- 基于Histogram的决策树算法
- 带深度限制的Leaf-wise的叶子生长策略
- 直方图做差加速
- 直接支持类别特征(Categorical Feature)
- Cache命中率优化
- 基于直方图的稀疏特征优化
- 多线程优化

![img](https://gitee.com/karlhan/picgo/raw/master/img//lightgbm.png)



























